{
    "num_heads=6_mlp_exp=3.5_embed_size=1024": [
        {
            "eval_loss": 6.0512,
            "eval_runtime": 39.1275,
            "eval_samples_per_second": 25.557,
            "eval_steps_per_second": 6.389,
            "epoch": 0.035555555555555556,
            "step": 5
        },
        {
            "loss": 6.1599,
            "grad_norm": 10.6875,
            "learning_rate": 0.0002,
            "epoch": 0.035555555555555556,
            "step": 5
        },
        {
            "loss": 5.0337,
            "grad_norm": 3.796875,
            "learning_rate": 0.00019983691039261357,
            "epoch": 0.07111111111111111,
            "step": 10
        },
        {
            "loss": 4.459,
            "grad_norm": 2.671875,
            "learning_rate": 0.00019934817353485501,
            "epoch": 0.10666666666666667,
            "step": 15
        },
        {
            "loss": 4.1106,
            "grad_norm": 2.125,
            "learning_rate": 0.00019853538358476932,
            "epoch": 0.14222222222222222,
            "step": 20
        },
        {
            "loss": 3.9238,
            "grad_norm": 1.703125,
            "learning_rate": 0.00019740119169423337,
            "epoch": 0.17777777777777778,
            "step": 25
        },
        {
            "loss": 3.8018,
            "grad_norm": 1.7421875,
            "learning_rate": 0.00019594929736144976,
            "epoch": 0.21333333333333335,
            "step": 30
        },
        {
            "eval_loss": 3.360351085662842,
            "eval_runtime": 39.1275,
            "eval_samples_per_second": 25.557,
            "eval_steps_per_second": 6.389,
            "epoch": 0.21333333333333335,
            "step": 30
        },
        {
            "loss": 3.686,
            "grad_norm": 1.4140625,
            "learning_rate": 0.00019418443636395248,
            "epoch": 0.24888888888888888,
            "step": 35
        },
        {
            "loss": 3.592,
            "grad_norm": 1.5859375,
            "learning_rate": 0.000192112365311485,
            "epoch": 0.28444444444444444,
            "step": 40
        },
        {
            "loss": 3.575,
            "grad_norm": 1.3359375,
            "learning_rate": 0.00018973984286913584,
            "epoch": 0.32,
            "step": 45
        },
        {
            "loss": 3.5154,
            "grad_norm": 1.1015625,
            "learning_rate": 0.00018707460771197774,
            "epoch": 0.35555555555555557,
            "step": 50
        },
        {
            "loss": 3.5052,
            "grad_norm": 1.1875,
            "learning_rate": 0.00018412535328311814,
            "epoch": 0.39111111111111113,
            "step": 55
        },
        {
            "loss": 3.4359,
            "grad_norm": 1.1875,
            "learning_rate": 0.00018090169943749476,
            "epoch": 0.4266666666666667,
            "step": 60
        },
        {
            "eval_loss": 3.1864240169525146,
            "eval_runtime": 33.0681,
            "eval_samples_per_second": 30.241,
            "eval_steps_per_second": 7.56,
            "epoch": 0.4266666666666667,
            "step": 60
        },
        {
            "loss": 3.4504,
            "grad_norm": 0.98046875,
            "learning_rate": 0.00017741416106390826,
            "epoch": 0.4622222222222222,
            "step": 65
        },
        {
            "loss": 3.4502,
            "grad_norm": 0.9140625,
            "learning_rate": 0.0001736741137876405,
            "epoch": 0.49777777777777776,
            "step": 70
        },
        {
            "loss": 3.4116,
            "grad_norm": 0.98828125,
            "learning_rate": 0.00016969375686552937,
            "epoch": 0.5333333333333333,
            "step": 75
        },
        {
            "loss": 3.3667,
            "grad_norm": 0.95703125,
            "learning_rate": 0.00016548607339452853,
            "epoch": 0.5688888888888889,
            "step": 80
        },
        {
            "loss": 3.383,
            "grad_norm": 0.9765625,
            "learning_rate": 0.00016106478796354382,
            "epoch": 0.6044444444444445,
            "step": 85
        },
        {
            "loss": 3.3502,
            "grad_norm": 1.015625,
            "learning_rate": 0.00015644432188667695,
            "epoch": 0.64,
            "step": 90
        },
        {
            "eval_loss": 3.12829852104187,
            "eval_runtime": 33.8924,
            "eval_samples_per_second": 29.505,
            "eval_steps_per_second": 7.376,
            "epoch": 0.64,
            "step": 90
        },
        {
            "loss": 3.341,
            "grad_norm": 0.8984375,
            "learning_rate": 0.0001516397461638962,
            "epoch": 0.6755555555555556,
            "step": 95
        },
        {
            "loss": 3.3387,
            "grad_norm": 1.0625,
            "learning_rate": 0.00014666673232256738,
            "epoch": 0.7111111111111111,
            "step": 100
        },
        {
            "loss": 3.3668,
            "grad_norm": 0.94921875,
            "learning_rate": 0.00014154150130018866,
            "epoch": 0.7466666666666667,
            "step": 105
        },
        {
            "loss": 3.3017,
            "grad_norm": 0.94140625,
            "learning_rate": 0.0001362807705350641,
            "epoch": 0.7822222222222223,
            "step": 110
        },
        {
            "loss": 3.3033,
            "grad_norm": 0.95703125,
            "learning_rate": 0.00013090169943749476,
            "epoch": 0.8177777777777778,
            "step": 115
        },
        {
            "loss": 3.3156,
            "grad_norm": 0.94140625,
            "learning_rate": 0.00012542183341934872,
            "epoch": 0.8533333333333334,
            "step": 120
        },
        {
            "eval_loss": 3.1019704341888428,
            "eval_runtime": 40.3323,
            "eval_samples_per_second": 24.794,
            "eval_steps_per_second": 6.199,
            "epoch": 0.8533333333333334,
            "step": 120
        },
        {
            "loss": 3.3281,
            "grad_norm": 0.91015625,
            "learning_rate": 0.00011985904666457455,
            "epoch": 0.8888888888888888,
            "step": 125
        },
        {
            "loss": 3.3234,
            "grad_norm": 0.97265625,
            "learning_rate": 0.00011423148382732853,
            "epoch": 0.9244444444444444,
            "step": 130
        },
        {
            "loss": 3.3016,
            "grad_norm": 0.88671875,
            "learning_rate": 0.00010855750084788398,
            "epoch": 0.96,
            "step": 135
        },
        {
            "loss": 3.3101,
            "grad_norm": 0.82421875,
            "learning_rate": 0.00010285560507936961,
            "epoch": 0.9955555555555555,
            "step": 140
        },
        {
            "loss": 3.904,
            "grad_norm": 0.83984375,
            "learning_rate": 9.71443949206304e-05,
            "epoch": 1.0355555555555556,
            "step": 145
        },
        {
            "loss": 3.2583,
            "grad_norm": 0.8515625,
            "learning_rate": 9.144249915211605e-05,
            "epoch": 1.0711111111111111,
            "step": 150
        },
        {
            "eval_loss": 3.0929312705993652,
            "eval_runtime": 39.7087,
            "eval_samples_per_second": 25.183,
            "eval_steps_per_second": 6.296,
            "epoch": 1.0711111111111111,
            "step": 150
        },
        {
            "loss": 3.2539,
            "grad_norm": 0.77734375,
            "learning_rate": 8.57685161726715e-05,
            "epoch": 1.1066666666666667,
            "step": 155
        },
        {
            "loss": 3.2492,
            "grad_norm": 0.83203125,
            "learning_rate": 8.014095333542548e-05,
            "epoch": 1.1422222222222222,
            "step": 160
        },
        {
            "loss": 3.2434,
            "grad_norm": 0.8359375,
            "learning_rate": 7.457816658065134e-05,
            "epoch": 1.1777777777777778,
            "step": 165
        },
        {
            "loss": 3.2753,
            "grad_norm": 0.8046875,
            "learning_rate": 6.909830056250527e-05,
            "epoch": 1.2133333333333334,
            "step": 170
        },
        {
            "loss": 3.2258,
            "grad_norm": 0.87890625,
            "learning_rate": 6.371922946493591e-05,
            "epoch": 1.248888888888889,
            "step": 175
        },
        {
            "loss": 3.245,
            "grad_norm": 0.91796875,
            "learning_rate": 5.845849869981137e-05,
            "epoch": 1.2844444444444445,
            "step": 180
        },
        {
            "eval_loss": 3.0851521492004395,
            "eval_runtime": 33.0805,
            "eval_samples_per_second": 30.229,
            "eval_steps_per_second": 7.557,
            "epoch": 1.2844444444444445,
            "step": 180
        },
        {
            "loss": 3.2833,
            "grad_norm": 0.82421875,
            "learning_rate": 5.333326767743263e-05,
            "epoch": 1.32,
            "step": 185
        },
        {
            "loss": 3.2426,
            "grad_norm": 0.81640625,
            "learning_rate": 4.836025383610382e-05,
            "epoch": 1.3555555555555556,
            "step": 190
        },
        {
            "loss": 3.2405,
            "grad_norm": 0.89453125,
            "learning_rate": 4.355567811332311e-05,
            "epoch": 1.3911111111111112,
            "step": 195
        },
        {
            "loss": 3.2137,
            "grad_norm": 0.86328125,
            "learning_rate": 3.893521203645618e-05,
            "epoch": 1.4266666666666667,
            "step": 200
        },
        {
            "loss": 3.2661,
            "grad_norm": 0.8125,
            "learning_rate": 3.45139266054715e-05,
            "epoch": 1.462222222222222,
            "step": 205
        },
        {
            "loss": 3.2549,
            "grad_norm": 0.85546875,
            "learning_rate": 3.030624313447067e-05,
            "epoch": 1.4977777777777779,
            "step": 210
        },
        {
            "eval_loss": 3.08383846282959,
            "eval_runtime": 32.8122,
            "eval_samples_per_second": 30.476,
            "eval_steps_per_second": 7.619,
            "epoch": 1.4977777777777779,
            "step": 210
        },
        {
            "loss": 3.2504,
            "grad_norm": 0.7890625,
            "learning_rate": 2.6325886212359498e-05,
            "epoch": 1.5333333333333332,
            "step": 215
        },
        {
            "loss": 3.2444,
            "grad_norm": 0.88671875,
            "learning_rate": 2.2585838936091754e-05,
            "epoch": 1.568888888888889,
            "step": 220
        },
        {
            "loss": 3.2943,
            "grad_norm": 0.80859375,
            "learning_rate": 1.9098300562505266e-05,
            "epoch": 1.6044444444444443,
            "step": 225
        },
        {
            "loss": 3.2761,
            "grad_norm": 0.890625,
            "learning_rate": 1.587464671688187e-05,
            "epoch": 1.6400000000000001,
            "step": 230
        },
        {
            "loss": 3.2772,
            "grad_norm": 0.86328125,
            "learning_rate": 1.2925392288022298e-05,
            "epoch": 1.6755555555555555,
            "step": 235
        },
        {
            "loss": 3.2242,
            "grad_norm": 0.890625,
            "learning_rate": 1.026015713086418e-05,
            "epoch": 1.7111111111111112,
            "step": 240
        },
        {
            "eval_loss": 3.0832080841064453,
            "eval_runtime": 39.3111,
            "eval_samples_per_second": 25.438,
            "eval_steps_per_second": 6.36,
            "epoch": 1.7111111111111112,
            "step": 240
        },
        {
            "loss": 3.2337,
            "grad_norm": 0.8359375,
            "learning_rate": 7.887634688515e-06,
            "epoch": 1.7466666666666666,
            "step": 245
        },
        {
            "loss": 3.2459,
            "grad_norm": 0.828125,
            "learning_rate": 5.8155636360475385e-06,
            "epoch": 1.7822222222222224,
            "step": 250
        },
        {
            "loss": 3.2548,
            "grad_norm": 0.78125,
            "learning_rate": 4.050702638550275e-06,
            "epoch": 1.8177777777777777,
            "step": 255
        },
        {
            "loss": 3.2111,
            "grad_norm": 0.85546875,
            "learning_rate": 2.5988083057666533e-06,
            "epoch": 1.8533333333333335,
            "step": 260
        },
        {
            "loss": 3.2515,
            "grad_norm": 0.80078125,
            "learning_rate": 1.4646164152307018e-06,
            "epoch": 1.8888888888888888,
            "step": 265
        },
        {
            "loss": 3.2295,
            "grad_norm": 0.84765625,
            "learning_rate": 6.518264651449779e-07,
            "epoch": 1.9244444444444444,
            "step": 270
        },
        {
            "eval_loss": 3.08321475982666,
            "eval_runtime": 36.8379,
            "eval_samples_per_second": 27.146,
            "eval_steps_per_second": 6.786,
            "epoch": 1.9244444444444444,
            "step": 270
        },
        {
            "loss": 3.2691,
            "grad_norm": 0.7734375,
            "learning_rate": 1.630896073864352e-07,
            "epoch": 1.96,
            "step": 275
        },
        {
            "loss": 3.2199,
            "grad_norm": 0.87109375,
            "learning_rate": 0.0,
            "epoch": 1.9955555555555555,
            "step": 280
        },
        {
            "train_runtime": 2148.6789,
            "train_samples_per_second": 8.377,
            "train_steps_per_second": 0.13,
            "total_flos": 2.259779039482675e+16,
            "train_loss": 3.4656900678362166,
            "epoch": 1.9955555555555555,
            "step": 280
        }
    ],
    "num_heads=10_mlp_exp=3_embed_size=1024": [
        {
            "eval_loss": 6.738983812,
            "eval_runtime": 35.9422,
            "eval_samples_per_second": 27.822,
            "eval_steps_per_second": 6.956,
            "epoch": 0.035555555555555556,
            "step": 5
        },
        {
            "loss": 7.009,
            "grad_norm": 9.9375,
            "learning_rate": 0.0002,
            "epoch": 0.035555555555555556,
            "step": 5
        },
        {
            "loss": 5.5774,
            "grad_norm": 5.9375,
            "learning_rate": 0.00019983691039261357,
            "epoch": 0.07111111111111111,
            "step": 10
        },
        {
            "loss": 4.8318,
            "grad_norm": 3.171875,
            "learning_rate": 0.00019934817353485501,
            "epoch": 0.10666666666666667,
            "step": 15
        },
        {
            "loss": 4.3244,
            "grad_norm": 2.375,
            "learning_rate": 0.00019853538358476932,
            "epoch": 0.14222222222222222,
            "step": 20
        },
        {
            "loss": 4.0462,
            "grad_norm": 1.9609375,
            "learning_rate": 0.00019740119169423337,
            "epoch": 0.17777777777777778,
            "step": 25
        },
        {
            "loss": 3.8399,
            "grad_norm": 1.703125,
            "learning_rate": 0.00019594929736144976,
            "epoch": 0.21333333333333335,
            "step": 30
        },
        {
            "eval_loss": 3.4019527435302734,
            "eval_runtime": 35.9422,
            "eval_samples_per_second": 27.822,
            "eval_steps_per_second": 6.956,
            "epoch": 0.21333333333333335,
            "step": 30
        },
        {
            "loss": 3.6686,
            "grad_norm": 1.5390625,
            "learning_rate": 0.00019418443636395248,
            "epoch": 0.24888888888888888,
            "step": 35
        },
        {
            "loss": 3.5528,
            "grad_norm": 1.328125,
            "learning_rate": 0.000192112365311485,
            "epoch": 0.28444444444444444,
            "step": 40
        },
        {
            "loss": 3.5045,
            "grad_norm": 1.4296875,
            "learning_rate": 0.00018973984286913584,
            "epoch": 0.32,
            "step": 45
        },
        {
            "loss": 3.4311,
            "grad_norm": 1.2265625,
            "learning_rate": 0.00018707460771197774,
            "epoch": 0.35555555555555557,
            "step": 50
        },
        {
            "loss": 3.4144,
            "grad_norm": 1.140625,
            "learning_rate": 0.00018412535328311814,
            "epoch": 0.39111111111111113,
            "step": 55
        },
        {
            "loss": 3.3377,
            "grad_norm": 1.234375,
            "learning_rate": 0.00018090169943749476,
            "epoch": 0.4266666666666667,
            "step": 60
        },
        {
            "eval_loss": 3.125411033630371,
            "eval_runtime": 38.9244,
            "eval_samples_per_second": 25.691,
            "eval_steps_per_second": 6.423,
            "epoch": 0.4266666666666667,
            "step": 60
        },
        {
            "loss": 3.3503,
            "grad_norm": 1.1171875,
            "learning_rate": 0.00017741416106390826,
            "epoch": 0.4622222222222222,
            "step": 65
        },
        {
            "loss": 3.3492,
            "grad_norm": 0.99609375,
            "learning_rate": 0.0001736741137876405,
            "epoch": 0.49777777777777776,
            "step": 70
        },
        {
            "loss": 3.3103,
            "grad_norm": 1.015625,
            "learning_rate": 0.00016969375686552937,
            "epoch": 0.5333333333333333,
            "step": 75
        },
        {
            "loss": 3.2673,
            "grad_norm": 1.0078125,
            "learning_rate": 0.00016548607339452853,
            "epoch": 0.5688888888888889,
            "step": 80
        },
        {
            "loss": 3.2796,
            "grad_norm": 0.953125,
            "learning_rate": 0.00016106478796354382,
            "epoch": 0.6044444444444445,
            "step": 85
        },
        {
            "loss": 3.2525,
            "grad_norm": 1.0625,
            "learning_rate": 0.00015644432188667695,
            "epoch": 0.64,
            "step": 90
        },
        {
            "eval_loss": 3.068044662475586,
            "eval_runtime": 23.5142,
            "eval_samples_per_second": 42.528,
            "eval_steps_per_second": 10.632,
            "epoch": 0.64,
            "step": 90
        },
        {
            "loss": 3.2447,
            "grad_norm": 0.98828125,
            "learning_rate": 0.0001516397461638962,
            "epoch": 0.6755555555555556,
            "step": 95
        },
        {
            "loss": 3.2442,
            "grad_norm": 1.046875,
            "learning_rate": 0.00014666673232256738,
            "epoch": 0.7111111111111111,
            "step": 100
        },
        {
            "loss": 3.2825,
            "grad_norm": 0.9765625,
            "learning_rate": 0.00014154150130018866,
            "epoch": 0.7466666666666667,
            "step": 105
        },
        {
            "loss": 3.21,
            "grad_norm": 0.9375,
            "learning_rate": 0.0001362807705350641,
            "epoch": 0.7822222222222223,
            "step": 110
        },
        {
            "loss": 3.2034,
            "grad_norm": 0.98828125,
            "learning_rate": 0.00013090169943749476,
            "epoch": 0.8177777777777778,
            "step": 115
        },
        {
            "loss": 3.2227,
            "grad_norm": 0.9921875,
            "learning_rate": 0.00012542183341934872,
            "epoch": 0.8533333333333334,
            "step": 120
        },
        {
            "eval_loss": 3.043403387069702,
            "eval_runtime": 32.2294,
            "eval_samples_per_second": 31.028,
            "eval_steps_per_second": 7.757,
            "epoch": 0.8533333333333334,
            "step": 120
        },
        {
            "loss": 3.2269,
            "grad_norm": 0.8828125,
            "learning_rate": 0.00011985904666457455,
            "epoch": 0.8888888888888888,
            "step": 125
        },
        {
            "loss": 3.2381,
            "grad_norm": 0.94140625,
            "learning_rate": 0.00011423148382732853,
            "epoch": 0.9244444444444444,
            "step": 130
        },
        {
            "loss": 3.2099,
            "grad_norm": 0.90234375,
            "learning_rate": 0.00010855750084788398,
            "epoch": 0.96,
            "step": 135
        },
        {
            "loss": 3.23,
            "grad_norm": 0.84375,
            "learning_rate": 0.00010285560507936961,
            "epoch": 0.9955555555555555,
            "step": 140
        },
        {
            "loss": 3.8007,
            "grad_norm": 0.88671875,
            "learning_rate": 9.71443949206304e-05,
            "epoch": 1.0355555555555556,
            "step": 145
        },
        {
            "loss": 3.173,
            "grad_norm": 0.890625,
            "learning_rate": 9.144249915211605e-05,
            "epoch": 1.0711111111111111,
            "step": 150
        },
        {
            "eval_loss": 3.0335655212402344,
            "eval_runtime": 32.4273,
            "eval_samples_per_second": 30.838,
            "eval_steps_per_second": 7.71,
            "epoch": 1.0711111111111111,
            "step": 150
        },
        {
            "loss": 3.1704,
            "grad_norm": 0.85546875,
            "learning_rate": 8.57685161726715e-05,
            "epoch": 1.1066666666666667,
            "step": 155
        },
        {
            "loss": 3.1563,
            "grad_norm": 0.83203125,
            "learning_rate": 8.014095333542548e-05,
            "epoch": 1.1422222222222222,
            "step": 160
        },
        {
            "loss": 3.1562,
            "grad_norm": 0.83203125,
            "learning_rate": 7.457816658065134e-05,
            "epoch": 1.1777777777777778,
            "step": 165
        },
        {
            "loss": 3.1968,
            "grad_norm": 0.82421875,
            "learning_rate": 6.909830056250527e-05,
            "epoch": 1.2133333333333334,
            "step": 170
        },
        {
            "loss": 3.1427,
            "grad_norm": 0.8359375,
            "learning_rate": 6.371922946493591e-05,
            "epoch": 1.248888888888889,
            "step": 175
        },
        {
            "loss": 3.1623,
            "grad_norm": 0.8984375,
            "learning_rate": 5.845849869981137e-05,
            "epoch": 1.2844444444444445,
            "step": 180
        },
        {
            "eval_loss": 3.0275321006774902,
            "eval_runtime": 30.0329,
            "eval_samples_per_second": 33.297,
            "eval_steps_per_second": 8.324,
            "epoch": 1.2844444444444445,
            "step": 180
        },
        {
            "loss": 3.1994,
            "grad_norm": 0.83203125,
            "learning_rate": 5.333326767743263e-05,
            "epoch": 1.32,
            "step": 185
        },
        {
            "loss": 3.15,
            "grad_norm": 0.82421875,
            "learning_rate": 4.836025383610382e-05,
            "epoch": 1.3555555555555556,
            "step": 190
        },
        {
            "loss": 3.1519,
            "grad_norm": 0.8203125,
            "learning_rate": 4.355567811332311e-05,
            "epoch": 1.3911111111111112,
            "step": 195
        },
        {
            "loss": 3.1321,
            "grad_norm": 0.84375,
            "learning_rate": 3.893521203645618e-05,
            "epoch": 1.4266666666666667,
            "step": 200
        },
        {
            "loss": 3.1832,
            "grad_norm": 0.8046875,
            "learning_rate": 3.45139266054715e-05,
            "epoch": 1.462222222222222,
            "step": 205
        },
        {
            "loss": 3.1662,
            "grad_norm": 0.859375,
            "learning_rate": 3.030624313447067e-05,
            "epoch": 1.4977777777777779,
            "step": 210
        },
        {
            "eval_loss": 3.0254921913146973,
            "eval_runtime": 29.5447,
            "eval_samples_per_second": 33.847,
            "eval_steps_per_second": 8.462,
            "epoch": 1.4977777777777779,
            "step": 210
        },
        {
            "loss": 3.1705,
            "grad_norm": 0.7265625,
            "learning_rate": 2.6325886212359498e-05,
            "epoch": 1.5333333333333332,
            "step": 215
        },
        {
            "loss": 3.1568,
            "grad_norm": 0.84375,
            "learning_rate": 2.2585838936091754e-05,
            "epoch": 1.568888888888889,
            "step": 220
        },
        {
            "loss": 3.2048,
            "grad_norm": 0.78125,
            "learning_rate": 1.9098300562505266e-05,
            "epoch": 1.6044444444444443,
            "step": 225
        },
        {
            "loss": 3.1988,
            "grad_norm": 0.88671875,
            "learning_rate": 1.587464671688187e-05,
            "epoch": 1.6400000000000001,
            "step": 230
        },
        {
            "loss": 3.1841,
            "grad_norm": 0.83984375,
            "learning_rate": 1.2925392288022298e-05,
            "epoch": 1.6755555555555555,
            "step": 235
        },
        {
            "loss": 3.1399,
            "grad_norm": 0.86328125,
            "learning_rate": 1.026015713086418e-05,
            "epoch": 1.7111111111111112,
            "step": 240
        },
        {
            "eval_loss": 3.0250051021575928,
            "eval_runtime": 32.2152,
            "eval_samples_per_second": 31.041,
            "eval_steps_per_second": 7.76,
            "epoch": 1.7111111111111112,
            "step": 240
        },
        {
            "loss": 3.1543,
            "grad_norm": 0.78515625,
            "learning_rate": 7.887634688515e-06,
            "epoch": 1.7466666666666666,
            "step": 245
        },
        {
            "loss": 3.1639,
            "grad_norm": 0.859375,
            "learning_rate": 5.8155636360475385e-06,
            "epoch": 1.7822222222222224,
            "step": 250
        },
        {
            "loss": 3.1702,
            "grad_norm": 0.83203125,
            "learning_rate": 4.050702638550275e-06,
            "epoch": 1.8177777777777777,
            "step": 255
        },
        {
            "loss": 3.1271,
            "grad_norm": 0.84765625,
            "learning_rate": 2.5988083057666533e-06,
            "epoch": 1.8533333333333335,
            "step": 260
        },
        {
            "loss": 3.1693,
            "grad_norm": 0.76953125,
            "learning_rate": 1.4646164152307018e-06,
            "epoch": 1.8888888888888888,
            "step": 265
        },
        {
            "loss": 3.1462,
            "grad_norm": 0.8125,
            "learning_rate": 6.518264651449779e-07,
            "epoch": 1.9244444444444444,
            "step": 270
        },
        {
            "eval_loss": 3.0250813961029053,
            "eval_runtime": 35.3541,
            "eval_samples_per_second": 28.285,
            "eval_steps_per_second": 7.071,
            "epoch": 1.9244444444444444,
            "step": 270
        },
        {
            "loss": 3.1803,
            "grad_norm": 0.7734375,
            "learning_rate": 1.630896073864352e-07,
            "epoch": 1.96,
            "step": 275
        },
        {
            "loss": 3.1248,
            "grad_norm": 0.82421875,
            "learning_rate": 0.0,
            "epoch": 1.9955555555555555,
            "step": 280
        },
        {
            "train_runtime": 2051.7895,
            "train_samples_per_second": 8.773,
            "train_steps_per_second": 0.136,
            "total_flos": 2.2598438660653056e+16,
            "train_loss": 3.426635909080505,
            "epoch": 1.9955555555555555,
            "step": 280
        }
    ],
    "num_heads=12_mlp_exp=2.5_embed_size=1024": [
        {
            "eval_loss": 7.2583,
            "eval_runtime": 31.1857,
            "eval_samples_per_second": 32.066,
            "eval_steps_per_second": 8.016,
            "epoch": 0.035555555555555556,
            "step": 5
        },
        {
            "loss": 7.4441,
            "grad_norm": 16.0,
            "learning_rate": 0.0005,
            "epoch": 0.035555555555555556,
            "step": 5
        },
        {
            "loss": 5.9723,
            "grad_norm": 6.5625,
            "learning_rate": 0.0004995922759815339,
            "epoch": 0.07111111111111111,
            "step": 10
        },
        {
            "loss": 5.1808,
            "grad_norm": 4.15625,
            "learning_rate": 0.0004983704338371376,
            "epoch": 0.10666666666666667,
            "step": 15
        },
        {
            "loss": 4.4943,
            "grad_norm": 1.8125,
            "learning_rate": 0.0004963384589619233,
            "epoch": 0.14222222222222222,
            "step": 20
        },
        {
            "loss": 4.072,
            "grad_norm": 1.3359375,
            "learning_rate": 0.0004935029792355834,
            "epoch": 0.17777777777777778,
            "step": 25
        },
        {
            "loss": 3.7855,
            "grad_norm": 1.0859375,
            "learning_rate": 0.0004898732434036243,
            "epoch": 0.21333333333333335,
            "step": 30
        },
        {
            "eval_loss": 3.4150381088256836,
            "eval_runtime": 31.1857,
            "eval_samples_per_second": 32.066,
            "eval_steps_per_second": 8.016,
            "epoch": 0.21333333333333335,
            "step": 30
        },
        {
            "loss": 3.5877,
            "grad_norm": 0.91796875,
            "learning_rate": 0.0004854610909098812,
            "epoch": 0.24888888888888888,
            "step": 35
        },
        {
            "loss": 3.4848,
            "grad_norm": 0.80859375,
            "learning_rate": 0.00048028091327871256,
            "epoch": 0.28444444444444444,
            "step": 40
        },
        {
            "loss": 3.4605,
            "grad_norm": 0.90234375,
            "learning_rate": 0.0004743496071728396,
            "epoch": 0.32,
            "step": 45
        },
        {
            "loss": 3.3977,
            "grad_norm": 0.78125,
            "learning_rate": 0.00046768651927994433,
            "epoch": 0.35555555555555557,
            "step": 50
        },
        {
            "loss": 3.4008,
            "grad_norm": 0.6484375,
            "learning_rate": 0.0004603133832077953,
            "epoch": 0.39111111111111113,
            "step": 55
        },
        {
            "loss": 3.3258,
            "grad_norm": 0.6640625,
            "learning_rate": 0.0004522542485937369,
            "epoch": 0.4266666666666667,
            "step": 60
        },
        {
            "eval_loss": 3.1584253311157227,
            "eval_runtime": 31.2443,
            "eval_samples_per_second": 32.006,
            "eval_steps_per_second": 8.001,
            "epoch": 0.4266666666666667,
            "step": 60
        },
        {
            "loss": 3.3446,
            "grad_norm": 0.73046875,
            "learning_rate": 0.00044353540265977065,
            "epoch": 0.4622222222222222,
            "step": 65
        },
        {
            "loss": 3.3552,
            "grad_norm": 0.7890625,
            "learning_rate": 0.00043418528446910123,
            "epoch": 0.49777777777777776,
            "step": 70
        },
        {
            "loss": 3.3156,
            "grad_norm": 0.6640625,
            "learning_rate": 0.00042423439216382345,
            "epoch": 0.5333333333333333,
            "step": 75
        },
        {
            "loss": 3.265,
            "grad_norm": 0.69140625,
            "learning_rate": 0.0004137151834863213,
            "epoch": 0.5688888888888889,
            "step": 80
        },
        {
            "loss": 3.2842,
            "grad_norm": 0.5703125,
            "learning_rate": 0.00040266196990885957,
            "epoch": 0.6044444444444445,
            "step": 85
        },
        {
            "loss": 3.2483,
            "grad_norm": 0.57421875,
            "learning_rate": 0.0003911108047166924,
            "epoch": 0.64,
            "step": 90
        },
        {
            "eval_loss": 3.094691514968872,
            "eval_runtime": 30.689,
            "eval_samples_per_second": 32.585,
            "eval_steps_per_second": 8.146,
            "epoch": 0.64,
            "step": 90
        },
        {
            "loss": 3.2457,
            "grad_norm": 0.5703125,
            "learning_rate": 0.0003790993654097405,
            "epoch": 0.6755555555555556,
            "step": 95
        },
        {
            "loss": 3.2436,
            "grad_norm": 0.6171875,
            "learning_rate": 0.00036666683080641843,
            "epoch": 0.7111111111111111,
            "step": 100
        },
        {
            "loss": 3.2804,
            "grad_norm": 0.66796875,
            "learning_rate": 0.00035385375325047166,
            "epoch": 0.7466666666666667,
            "step": 105
        },
        {
            "loss": 3.2049,
            "grad_norm": 0.6640625,
            "learning_rate": 0.00034070192633766023,
            "epoch": 0.7822222222222223,
            "step": 110
        },
        {
            "loss": 3.2026,
            "grad_norm": 0.671875,
            "learning_rate": 0.00032725424859373687,
            "epoch": 0.8177777777777778,
            "step": 115
        },
        {
            "loss": 3.2217,
            "grad_norm": 0.57421875,
            "learning_rate": 0.0003135545835483718,
            "epoch": 0.8533333333333334,
            "step": 120
        },
        {
            "eval_loss": 3.063284158706665,
            "eval_runtime": 31.2811,
            "eval_samples_per_second": 31.968,
            "eval_steps_per_second": 7.992,
            "epoch": 0.8533333333333334,
            "step": 120
        },
        {
            "loss": 3.2284,
            "grad_norm": 0.56640625,
            "learning_rate": 0.0002996476166614364,
            "epoch": 0.8888888888888888,
            "step": 125
        },
        {
            "loss": 3.2358,
            "grad_norm": 0.62109375,
            "learning_rate": 0.00028557870956832135,
            "epoch": 0.9244444444444444,
            "step": 130
        },
        {
            "loss": 3.1994,
            "grad_norm": 0.578125,
            "learning_rate": 0.00027139375211970997,
            "epoch": 0.96,
            "step": 135
        },
        {
            "loss": 3.2222,
            "grad_norm": 0.53125,
            "learning_rate": 0.00025713901269842405,
            "epoch": 0.9955555555555555,
            "step": 140
        },
        {
            "loss": 3.7016,
            "grad_norm": 0.63671875,
            "learning_rate": 0.00024286098730157596,
            "epoch": 1.0355555555555556,
            "step": 145
        },
        {
            "loss": 3.0656,
            "grad_norm": 0.61328125,
            "learning_rate": 0.00022860624788029015,
            "epoch": 1.0711111111111111,
            "step": 150
        },
        {
            "eval_loss": 3.0481700897216797,
            "eval_runtime": 31.2648,
            "eval_samples_per_second": 31.985,
            "eval_steps_per_second": 7.996,
            "epoch": 1.0711111111111111,
            "step": 150
        },
        {
            "loss": 3.0626,
            "grad_norm": 0.5625,
            "learning_rate": 0.00021442129043167875,
            "epoch": 1.1066666666666667,
            "step": 155
        },
        {
            "loss": 3.0547,
            "grad_norm": 0.546875,
            "learning_rate": 0.00020035238333856371,
            "epoch": 1.1422222222222222,
            "step": 160
        },
        {
            "loss": 3.0488,
            "grad_norm": 0.609375,
            "learning_rate": 0.00018644541645162832,
            "epoch": 1.1777777777777778,
            "step": 165
        },
        {
            "loss": 3.0883,
            "grad_norm": 0.58984375,
            "learning_rate": 0.00017274575140626317,
            "epoch": 1.2133333333333334,
            "step": 170
        },
        {
            "loss": 3.0362,
            "grad_norm": 0.52734375,
            "learning_rate": 0.00015929807366233978,
            "epoch": 1.248888888888889,
            "step": 175
        },
        {
            "loss": 3.0523,
            "grad_norm": 0.60546875,
            "learning_rate": 0.0001461462467495284,
            "epoch": 1.2844444444444445,
            "step": 180
        },
        {
            "eval_loss": 3.037252902984619,
            "eval_runtime": 31.2614,
            "eval_samples_per_second": 31.988,
            "eval_steps_per_second": 7.997,
            "epoch": 1.2844444444444445,
            "step": 180
        },
        {
            "loss": 3.0871,
            "grad_norm": 0.5,
            "learning_rate": 0.00013333316919358158,
            "epoch": 1.32,
            "step": 185
        },
        {
            "loss": 3.0352,
            "grad_norm": 0.4921875,
            "learning_rate": 0.00012090063459025954,
            "epoch": 1.3555555555555556,
            "step": 190
        },
        {
            "loss": 3.0442,
            "grad_norm": 0.84375,
            "learning_rate": 0.00010888919528330776,
            "epoch": 1.3911111111111112,
            "step": 195
        },
        {
            "loss": 3.018,
            "grad_norm": 0.5078125,
            "learning_rate": 9.733803009114044e-05,
            "epoch": 1.4266666666666667,
            "step": 200
        },
        {
            "loss": 3.0657,
            "grad_norm": 0.466796875,
            "learning_rate": 8.628481651367875e-05,
            "epoch": 1.462222222222222,
            "step": 205
        },
        {
            "loss": 3.0501,
            "grad_norm": 0.5546875,
            "learning_rate": 7.576560783617667e-05,
            "epoch": 1.4977777777777779,
            "step": 210
        },
        {
            "eval_loss": 3.0334362983703613,
            "eval_runtime": 31.1617,
            "eval_samples_per_second": 32.091,
            "eval_steps_per_second": 8.023,
            "epoch": 1.4977777777777779,
            "step": 210
        },
        {
            "loss": 3.0603,
            "grad_norm": 0.478515625,
            "learning_rate": 6.581471553089874e-05,
            "epoch": 1.5333333333333332,
            "step": 215
        },
        {
            "loss": 3.0427,
            "grad_norm": 0.515625,
            "learning_rate": 5.646459734022938e-05,
            "epoch": 1.568888888888889,
            "step": 220
        },
        {
            "loss": 3.0968,
            "grad_norm": 0.48046875,
            "learning_rate": 4.7745751406263163e-05,
            "epoch": 1.6044444444444443,
            "step": 225
        },
        {
            "loss": 3.0884,
            "grad_norm": 0.546875,
            "learning_rate": 3.968661679220467e-05,
            "epoch": 1.6400000000000001,
            "step": 230
        },
        {
            "loss": 3.068,
            "grad_norm": 0.494140625,
            "learning_rate": 3.231348072005574e-05,
            "epoch": 1.6755555555555555,
            "step": 235
        },
        {
            "loss": 3.0311,
            "grad_norm": 0.482421875,
            "learning_rate": 2.5650392827160445e-05,
            "epoch": 1.7111111111111112,
            "step": 240
        },
        {
            "eval_loss": 3.0318491458892822,
            "eval_runtime": 31.2304,
            "eval_samples_per_second": 32.02,
            "eval_steps_per_second": 8.005,
            "epoch": 1.7111111111111112,
            "step": 240
        },
        {
            "loss": 3.0396,
            "grad_norm": 0.51171875,
            "learning_rate": 1.97190867212875e-05,
            "epoch": 1.7466666666666666,
            "step": 245
        },
        {
            "loss": 3.0514,
            "grad_norm": 0.5078125,
            "learning_rate": 1.4538909090118846e-05,
            "epoch": 1.7822222222222224,
            "step": 250
        },
        {
            "loss": 3.0533,
            "grad_norm": 0.486328125,
            "learning_rate": 1.0126756596375685e-05,
            "epoch": 1.8177777777777777,
            "step": 255
        },
        {
            "loss": 3.0155,
            "grad_norm": 0.515625,
            "learning_rate": 6.497020764416634e-06,
            "epoch": 1.8533333333333335,
            "step": 260
        },
        {
            "loss": 3.0582,
            "grad_norm": 0.5234375,
            "learning_rate": 3.6615410380767543e-06,
            "epoch": 1.8888888888888888,
            "step": 265
        },
        {
            "loss": 3.0397,
            "grad_norm": 0.51953125,
            "learning_rate": 1.6295661628624448e-06,
            "epoch": 1.9244444444444444,
            "step": 270
        },
        {
            "eval_loss": 3.0318057537078857,
            "eval_runtime": 31.2626,
            "eval_samples_per_second": 31.987,
            "eval_steps_per_second": 7.997,
            "epoch": 1.9244444444444444,
            "step": 270
        },
        {
            "loss": 3.0646,
            "grad_norm": 0.4765625,
            "learning_rate": 4.07724018466088e-07,
            "epoch": 1.96,
            "step": 275
        },
        {
            "loss": 3.0151,
            "grad_norm": 0.52734375,
            "learning_rate": 0.0,
            "epoch": 1.9955555555555555,
            "step": 280
        },
        {
            "train_runtime": 1980.9437,
            "train_samples_per_second": 9.087,
            "train_steps_per_second": 0.141,
            "total_flos": 2.127046611546931e+16,
            "train_loss": 3.389978279386248,
            "epoch": 1.9955555555555555,
            "step": 280
        }
    ],
    "untrained_num_heads=12_mlp_exp=2.5_embed_size=1024": [
        {
            "eval_loss": 10.4355,
            "eval_runtime": 22.5351,
            "eval_samples_per_second": 44.375,
            "eval_steps_per_second": 11.094,
            "epoch": 0.035555555555555556,
            "step": 5
        },
        {
            "loss": 10.688,
            "grad_norm": 8.9375,
            "learning_rate": 0.0005,
            "epoch": 0.035555555555555556,
            "step": 5
        },
        {
            "loss": 8.8414,
            "grad_norm": 1.3203125,
            "learning_rate": 0.0004995922759815339,
            "epoch": 0.07111111111111111,
            "step": 10
        },
        {
            "loss": 7.7466,
            "grad_norm": 0.625,
            "learning_rate": 0.0004983704338371376,
            "epoch": 0.10666666666666667,
            "step": 15
        },
        {
            "loss": 7.6478,
            "grad_norm": 0.65234375,
            "learning_rate": 0.0004963384589619233,
            "epoch": 0.14222222222222222,
            "step": 20
        },
        {
            "loss": 7.6471,
            "grad_norm": 0.5,
            "learning_rate": 0.0004935029792355834,
            "epoch": 0.17777777777777778,
            "step": 25
        },
        {
            "loss": 7.6281,
            "grad_norm": 0.54296875,
            "learning_rate": 0.0004898732434036243,
            "epoch": 0.21333333333333335,
            "step": 30
        },
        {
            "eval_loss": 7.63228702545166,
            "eval_runtime": 22.5351,
            "eval_samples_per_second": 44.375,
            "eval_steps_per_second": 11.094,
            "epoch": 0.21333333333333335,
            "step": 30
        },
        {
            "loss": 7.6266,
            "grad_norm": 0.55078125,
            "learning_rate": 0.0004854610909098812,
            "epoch": 0.24888888888888888,
            "step": 35
        },
        {
            "loss": 7.5522,
            "grad_norm": 0.388671875,
            "learning_rate": 0.00048028091327871256,
            "epoch": 0.28444444444444444,
            "step": 40
        },
        {
            "loss": 7.604,
            "grad_norm": 0.431640625,
            "learning_rate": 0.0004743496071728396,
            "epoch": 0.32,
            "step": 45
        },
        {
            "loss": 7.545,
            "grad_norm": 0.359375,
            "learning_rate": 0.00046768651927994433,
            "epoch": 0.35555555555555557,
            "step": 50
        },
        {
            "loss": 7.5922,
            "grad_norm": 0.458984375,
            "learning_rate": 0.0004603133832077953,
            "epoch": 0.39111111111111113,
            "step": 55
        },
        {
            "loss": 7.5837,
            "grad_norm": 0.369140625,
            "learning_rate": 0.0004522542485937369,
            "epoch": 0.4266666666666667,
            "step": 60
        },
        {
            "eval_loss": 7.594008922576904,
            "eval_runtime": 22.4759,
            "eval_samples_per_second": 44.492,
            "eval_steps_per_second": 11.123,
            "epoch": 0.4266666666666667,
            "step": 60
        },
        {
            "loss": 7.5713,
            "grad_norm": 0.35546875,
            "learning_rate": 0.00044353540265977065,
            "epoch": 0.4622222222222222,
            "step": 65
        },
        {
            "loss": 7.5744,
            "grad_norm": 0.3515625,
            "learning_rate": 0.00043418528446910123,
            "epoch": 0.49777777777777776,
            "step": 70
        },
        {
            "loss": 7.5892,
            "grad_norm": 0.478515625,
            "learning_rate": 0.00042423439216382345,
            "epoch": 0.5333333333333333,
            "step": 75
        },
        {
            "loss": 7.5961,
            "grad_norm": 0.3515625,
            "learning_rate": 0.0004137151834863213,
            "epoch": 0.5688888888888889,
            "step": 80
        },
        {
            "loss": 7.5667,
            "grad_norm": 0.345703125,
            "learning_rate": 0.00040266196990885957,
            "epoch": 0.6044444444444445,
            "step": 85
        },
        {
            "loss": 7.5372,
            "grad_norm": 0.322265625,
            "learning_rate": 0.0003911108047166924,
            "epoch": 0.64,
            "step": 90
        },
        {
            "eval_loss": 7.57914924621582,
            "eval_runtime": 22.4954,
            "eval_samples_per_second": 44.453,
            "eval_steps_per_second": 11.113,
            "epoch": 0.64,
            "step": 90
        },
        {
            "loss": 7.5133,
            "grad_norm": 0.322265625,
            "learning_rate": 0.0003790993654097405,
            "epoch": 0.6755555555555556,
            "step": 95
        },
        {
            "loss": 7.552,
            "grad_norm": 0.392578125,
            "learning_rate": 0.00036666683080641843,
            "epoch": 0.7111111111111111,
            "step": 100
        },
        {
            "loss": 7.5555,
            "grad_norm": 0.306640625,
            "learning_rate": 0.00035385375325047166,
            "epoch": 0.7466666666666667,
            "step": 105
        },
        {
            "loss": 7.521,
            "grad_norm": 0.30859375,
            "learning_rate": 0.00034070192633766023,
            "epoch": 0.7822222222222223,
            "step": 110
        },
        {
            "loss": 7.5723,
            "grad_norm": 0.427734375,
            "learning_rate": 0.00032725424859373687,
            "epoch": 0.8177777777777778,
            "step": 115
        },
        {
            "loss": 7.5519,
            "grad_norm": 0.296875,
            "learning_rate": 0.0003135545835483718,
            "epoch": 0.8533333333333334,
            "step": 120
        },
        {
            "eval_loss": 7.564830303192139,
            "eval_runtime": 22.4852,
            "eval_samples_per_second": 44.474,
            "eval_steps_per_second": 11.118,
            "epoch": 0.8533333333333334,
            "step": 120
        },
        {
            "loss": 7.6005,
            "grad_norm": 0.439453125,
            "learning_rate": 0.0002996476166614364,
            "epoch": 0.8888888888888888,
            "step": 125
        },
        {
            "loss": 7.5116,
            "grad_norm": 0.2890625,
            "learning_rate": 0.00028557870956832135,
            "epoch": 0.9244444444444444,
            "step": 130
        },
        {
            "loss": 7.5202,
            "grad_norm": 0.267578125,
            "learning_rate": 0.00027139375211970997,
            "epoch": 0.96,
            "step": 135
        },
        {
            "loss": 7.486,
            "grad_norm": 0.2255859375,
            "learning_rate": 0.00025713901269842405,
            "epoch": 0.9955555555555555,
            "step": 140
        },
        {
            "loss": 8.9676,
            "grad_norm": 0.259765625,
            "learning_rate": 0.00024286098730157596,
            "epoch": 1.0355555555555556,
            "step": 145
        },
        {
            "loss": 7.5159,
            "grad_norm": 0.3203125,
            "learning_rate": 0.00022860624788029015,
            "epoch": 1.0711111111111111,
            "step": 150
        },
        {
            "eval_loss": 7.559723854064941,
            "eval_runtime": 22.4885,
            "eval_samples_per_second": 44.467,
            "eval_steps_per_second": 11.117,
            "epoch": 1.0711111111111111,
            "step": 150
        },
        {
            "loss": 7.4979,
            "grad_norm": 0.30859375,
            "learning_rate": 0.00021442129043167875,
            "epoch": 1.1066666666666667,
            "step": 155
        },
        {
            "loss": 7.5655,
            "grad_norm": 0.2734375,
            "learning_rate": 0.00020035238333856371,
            "epoch": 1.1422222222222222,
            "step": 160
        },
        {
            "loss": 7.5191,
            "grad_norm": 0.2470703125,
            "learning_rate": 0.00018644541645162832,
            "epoch": 1.1777777777777778,
            "step": 165
        },
        {
            "loss": 7.5115,
            "grad_norm": 0.33984375,
            "learning_rate": 0.00017274575140626317,
            "epoch": 1.2133333333333334,
            "step": 170
        },
        {
            "loss": 7.5056,
            "grad_norm": 0.302734375,
            "learning_rate": 0.00015929807366233978,
            "epoch": 1.248888888888889,
            "step": 175
        },
        {
            "loss": 7.514,
            "grad_norm": 0.330078125,
            "learning_rate": 0.0001461462467495284,
            "epoch": 1.2844444444444445,
            "step": 180
        },
        {
            "eval_loss": 7.552091598510742,
            "eval_runtime": 22.4854,
            "eval_samples_per_second": 44.473,
            "eval_steps_per_second": 11.118,
            "epoch": 1.2844444444444445,
            "step": 180
        },
        {
            "loss": 7.5446,
            "grad_norm": 0.259765625,
            "learning_rate": 0.00013333316919358158,
            "epoch": 1.32,
            "step": 185
        },
        {
            "loss": 7.5279,
            "grad_norm": 0.2265625,
            "learning_rate": 0.00012090063459025954,
            "epoch": 1.3555555555555556,
            "step": 190
        },
        {
            "loss": 7.5287,
            "grad_norm": 0.353515625,
            "learning_rate": 0.00010888919528330776,
            "epoch": 1.3911111111111112,
            "step": 195
        },
        {
            "loss": 7.4844,
            "grad_norm": 0.2333984375,
            "learning_rate": 9.733803009114044e-05,
            "epoch": 1.4266666666666667,
            "step": 200
        },
        {
            "loss": 7.561,
            "grad_norm": 0.287109375,
            "learning_rate": 8.628481651367875e-05,
            "epoch": 1.462222222222222,
            "step": 205
        },
        {
            "loss": 7.5172,
            "grad_norm": 0.2451171875,
            "learning_rate": 7.576560783617667e-05,
            "epoch": 1.4977777777777779,
            "step": 210
        },
        {
            "eval_loss": 7.548289775848389,
            "eval_runtime": 22.474,
            "eval_samples_per_second": 44.496,
            "eval_steps_per_second": 11.124,
            "epoch": 1.4977777777777779,
            "step": 210
        },
        {
            "loss": 7.49,
            "grad_norm": 0.2119140625,
            "learning_rate": 6.581471553089874e-05,
            "epoch": 1.5333333333333332,
            "step": 215
        },
        {
            "loss": 7.5317,
            "grad_norm": 0.37890625,
            "learning_rate": 5.646459734022938e-05,
            "epoch": 1.568888888888889,
            "step": 220
        },
        {
            "loss": 7.545,
            "grad_norm": 0.255859375,
            "learning_rate": 4.7745751406263163e-05,
            "epoch": 1.6044444444444443,
            "step": 225
        },
        {
            "loss": 7.4876,
            "grad_norm": 0.322265625,
            "learning_rate": 3.968661679220467e-05,
            "epoch": 1.6400000000000001,
            "step": 230
        },
        {
            "loss": 7.5445,
            "grad_norm": 0.296875,
            "learning_rate": 3.231348072005574e-05,
            "epoch": 1.6755555555555555,
            "step": 235
        },
        {
            "loss": 7.5159,
            "grad_norm": 0.271484375,
            "learning_rate": 2.5650392827160445e-05,
            "epoch": 1.7111111111111112,
            "step": 240
        },
        {
            "eval_loss": 7.546998977661133,
            "eval_runtime": 22.4842,
            "eval_samples_per_second": 44.476,
            "eval_steps_per_second": 11.119,
            "epoch": 1.7111111111111112,
            "step": 240
        },
        {
            "loss": 7.5221,
            "grad_norm": 0.291015625,
            "learning_rate": 1.97190867212875e-05,
            "epoch": 1.7466666666666666,
            "step": 245
        },
        {
            "loss": 7.4774,
            "grad_norm": 0.255859375,
            "learning_rate": 1.4538909090118846e-05,
            "epoch": 1.7822222222222224,
            "step": 250
        },
        {
            "loss": 7.5289,
            "grad_norm": 0.248046875,
            "learning_rate": 1.0126756596375685e-05,
            "epoch": 1.8177777777777777,
            "step": 255
        },
        {
            "loss": 7.4702,
            "grad_norm": 0.302734375,
            "learning_rate": 6.497020764416634e-06,
            "epoch": 1.8533333333333335,
            "step": 260
        },
        {
            "loss": 7.528,
            "grad_norm": 0.396484375,
            "learning_rate": 3.6615410380767543e-06,
            "epoch": 1.8888888888888888,
            "step": 265
        },
        {
            "loss": 7.5145,
            "grad_norm": 0.2734375,
            "learning_rate": 1.6295661628624448e-06,
            "epoch": 1.9244444444444444,
            "step": 270
        },
        {
            "eval_loss": 7.546879768371582,
            "eval_runtime": 22.4857,
            "eval_samples_per_second": 44.473,
            "eval_steps_per_second": 11.118,
            "epoch": 1.9244444444444444,
            "step": 270
        },
        {
            "loss": 7.5279,
            "grad_norm": 0.259765625,
            "learning_rate": 4.07724018466088e-07,
            "epoch": 1.96,
            "step": 275
        },
        {
            "loss": 7.5166,
            "grad_norm": 0.328125,
            "learning_rate": 0.0,
            "epoch": 1.9955555555555555,
            "step": 280
        },
        {
            "train_runtime": 1448.6466,
            "train_samples_per_second": 12.425,
            "train_steps_per_second": 0.193,
            "total_flos": 2.127046611546931e+16,
            "train_loss": 7.651481342315674,
            "epoch": 1.9955555555555555,
            "step": 280
        }
    ],
    "num_heads=16_hidden_size=4096_embed_size=768": [
        {
            "loss": 36.31,
            "grad_norm": 43.75,
            "learning_rate": 0.001,
            "epoch": 0.035555555555555556,
            "step": 5
        },
        {
            "loss": 12.1354,
            "grad_norm": 5.8125,
            "learning_rate": 0.0009991845519630679,
            "epoch": 0.07111111111111111,
            "step": 10
        },
        {
            "loss": 9.7788,
            "grad_norm": 2.6875,
            "learning_rate": 0.0009967408676742752,
            "epoch": 0.10666666666666667,
            "step": 15
        },
        {
            "loss": 8.4895,
            "grad_norm": 1.546875,
            "learning_rate": 0.0009926769179238466,
            "epoch": 0.14222222222222222,
            "step": 20
        },
        {
            "loss": 8.1017,
            "grad_norm": 1.1875,
            "learning_rate": 0.0009870059584711668,
            "epoch": 0.17777777777777778,
            "step": 25
        },
        {
            "loss": 7.8831,
            "grad_norm": 1.5234375,
            "learning_rate": 0.0009797464868072487,
            "epoch": 0.21333333333333335,
            "step": 30
        },
        {
            "eval_loss": 7.670154094696045,
            "eval_runtime": 36.5063,
            "eval_samples_per_second": 27.393,
            "eval_steps_per_second": 6.848,
            "epoch": 0.21333333333333335,
            "step": 30
        },
        {
            "loss": 7.7051,
            "grad_norm": 0.80078125,
            "learning_rate": 0.0009709221818197624,
            "epoch": 0.24888888888888888,
            "step": 35
        },
        {
            "loss": 7.4383,
            "grad_norm": 0.5546875,
            "learning_rate": 0.0009605618265574251,
            "epoch": 0.28444444444444444,
            "step": 40
        },
        {
            "loss": 7.3498,
            "grad_norm": 0.79296875,
            "learning_rate": 0.0009486992143456792,
            "epoch": 0.32,
            "step": 45
        },
        {
            "loss": 7.1939,
            "grad_norm": 2.28125,
            "learning_rate": 0.0009353730385598887,
            "epoch": 0.35555555555555557,
            "step": 50
        },
        {
            "loss": 7.1447,
            "grad_norm": 1.4921875,
            "learning_rate": 0.0009206267664155906,
            "epoch": 0.39111111111111113,
            "step": 55
        },
        {
            "loss": 7.008,
            "grad_norm": 1.015625,
            "learning_rate": 0.0009045084971874737,
            "epoch": 0.4266666666666667,
            "step": 60
        },
        {
            "eval_loss": 6.8657989501953125,
            "eval_runtime": 37.1786,
            "eval_samples_per_second": 26.897,
            "eval_steps_per_second": 6.724,
            "epoch": 0.4266666666666667,
            "step": 60
        },
        {
            "loss": 6.8732,
            "grad_norm": 0.8828125,
            "learning_rate": 0.0008870708053195413,
            "epoch": 0.4622222222222222,
            "step": 65
        },
        {
            "loss": 6.7913,
            "grad_norm": 0.6953125,
            "learning_rate": 0.0008683705689382025,
            "epoch": 0.49777777777777776,
            "step": 70
        },
        {
            "loss": 6.6978,
            "grad_norm": 0.78515625,
            "learning_rate": 0.0008484687843276469,
            "epoch": 0.5333333333333333,
            "step": 75
        },
        {
            "loss": 6.6658,
            "grad_norm": 0.87109375,
            "learning_rate": 0.0008274303669726426,
            "epoch": 0.5688888888888889,
            "step": 80
        },
        {
            "loss": 6.6035,
            "grad_norm": 0.84765625,
            "learning_rate": 0.0008053239398177191,
            "epoch": 0.6044444444444445,
            "step": 85
        },
        {
            "loss": 6.5075,
            "grad_norm": 0.88671875,
            "learning_rate": 0.0007822216094333848,
            "epoch": 0.64,
            "step": 90
        },
        {
            "eval_loss": 6.467623233795166,
            "eval_runtime": 36.296,
            "eval_samples_per_second": 27.551,
            "eval_steps_per_second": 6.888,
            "epoch": 0.64,
            "step": 90
        },
        {
            "loss": 6.4328,
            "grad_norm": 0.734375,
            "learning_rate": 0.000758198730819481,
            "epoch": 0.6755555555555556,
            "step": 95
        },
        {
            "loss": 6.446,
            "grad_norm": 0.7890625,
            "learning_rate": 0.0007333336616128369,
            "epoch": 0.7111111111111111,
            "step": 100
        },
        {
            "loss": 6.4197,
            "grad_norm": 0.52734375,
            "learning_rate": 0.0007077075065009433,
            "epoch": 0.7466666666666667,
            "step": 105
        },
        {
            "loss": 6.3234,
            "grad_norm": 0.53515625,
            "learning_rate": 0.0006814038526753205,
            "epoch": 0.7822222222222223,
            "step": 110
        },
        {
            "loss": 6.3561,
            "grad_norm": 0.7421875,
            "learning_rate": 0.0006545084971874737,
            "epoch": 0.8177777777777778,
            "step": 115
        },
        {
            "loss": 6.3018,
            "grad_norm": 0.94140625,
            "learning_rate": 0.0006271091670967436,
            "epoch": 0.8533333333333334,
            "step": 120
        },
        {
            "eval_loss": 6.2534003257751465,
            "eval_runtime": 36.2947,
            "eval_samples_per_second": 27.552,
            "eval_steps_per_second": 6.888,
            "epoch": 0.8533333333333334,
            "step": 120
        },
        {
            "loss": 6.336,
            "grad_norm": 1.375,
            "learning_rate": 0.0005992952333228728,
            "epoch": 0.8888888888888888,
            "step": 125
        },
        {
            "loss": 6.231,
            "grad_norm": 1.2109375,
            "learning_rate": 0.0005711574191366427,
            "epoch": 0.9244444444444444,
            "step": 130
        },
        {
            "loss": 6.2207,
            "grad_norm": 1.828125,
            "learning_rate": 0.0005427875042394199,
            "epoch": 0.96,
            "step": 135
        },
        {
            "loss": 6.1644,
            "grad_norm": 1.1171875,
            "learning_rate": 0.0005142780253968481,
            "epoch": 0.9955555555555555,
            "step": 140
        },
        {
            "loss": 7.3054,
            "grad_norm": 0.94921875,
            "learning_rate": 0.0004857219746031519,
            "epoch": 1.0355555555555556,
            "step": 145
        },
        {
            "loss": 6.1125,
            "grad_norm": 0.66796875,
            "learning_rate": 0.0004572124957605803,
            "epoch": 1.0711111111111111,
            "step": 150
        },
        {
            "eval_loss": 6.088733673095703,
            "eval_runtime": 36.2996,
            "eval_samples_per_second": 27.549,
            "eval_steps_per_second": 6.887,
            "epoch": 1.0711111111111111,
            "step": 150
        },
        {
            "loss": 6.0804,
            "grad_norm": 0.48046875,
            "learning_rate": 0.0004288425808633575,
            "epoch": 1.1066666666666667,
            "step": 155
        },
        {
            "loss": 6.111,
            "grad_norm": 0.546875,
            "learning_rate": 0.00040070476667712743,
            "epoch": 1.1422222222222222,
            "step": 160
        },
        {
            "loss": 6.0669,
            "grad_norm": 0.625,
            "learning_rate": 0.00037289083290325663,
            "epoch": 1.1777777777777778,
            "step": 165
        },
        {
            "loss": 6.0421,
            "grad_norm": 0.58984375,
            "learning_rate": 0.00034549150281252633,
            "epoch": 1.2133333333333334,
            "step": 170
        },
        {
            "loss": 6.0496,
            "grad_norm": 0.51953125,
            "learning_rate": 0.00031859614732467957,
            "epoch": 1.248888888888889,
            "step": 175
        },
        {
            "loss": 6.0258,
            "grad_norm": 0.4453125,
            "learning_rate": 0.0002922924934990568,
            "epoch": 1.2844444444444445,
            "step": 180
        },
        {
            "eval_loss": 6.003174781799316,
            "eval_runtime": 36.7063,
            "eval_samples_per_second": 27.243,
            "eval_steps_per_second": 6.811,
            "epoch": 1.2844444444444445,
            "step": 180
        },
        {
            "loss": 6.0532,
            "grad_norm": 0.3984375,
            "learning_rate": 0.00026666633838716316,
            "epoch": 1.32,
            "step": 185
        },
        {
            "loss": 6.0303,
            "grad_norm": 0.357421875,
            "learning_rate": 0.00024180126918051909,
            "epoch": 1.3555555555555556,
            "step": 190
        },
        {
            "loss": 6.0158,
            "grad_norm": 0.392578125,
            "learning_rate": 0.00021777839056661552,
            "epoch": 1.3911111111111112,
            "step": 195
        },
        {
            "loss": 5.9589,
            "grad_norm": 0.310546875,
            "learning_rate": 0.0001946760601822809,
            "epoch": 1.4266666666666667,
            "step": 200
        },
        {
            "loss": 6.0305,
            "grad_norm": 0.322265625,
            "learning_rate": 0.0001725696330273575,
            "epoch": 1.462222222222222,
            "step": 205
        },
        {
            "loss": 6.009,
            "grad_norm": 0.361328125,
            "learning_rate": 0.00015153121567235335,
            "epoch": 1.4977777777777779,
            "step": 210
        },
        {
            "eval_loss": 5.958104610443115,
            "eval_runtime": 36.3131,
            "eval_samples_per_second": 27.538,
            "eval_steps_per_second": 6.885,
            "epoch": 1.4977777777777779,
            "step": 210
        },
        {
            "loss": 5.9612,
            "grad_norm": 0.5078125,
            "learning_rate": 0.00013162943106179747,
            "epoch": 1.5333333333333332,
            "step": 215
        },
        {
            "loss": 5.977,
            "grad_norm": 0.396484375,
            "learning_rate": 0.00011292919468045875,
            "epoch": 1.568888888888889,
            "step": 220
        },
        {
            "loss": 6.021,
            "grad_norm": 0.4375,
            "learning_rate": 9.549150281252633e-05,
            "epoch": 1.6044444444444443,
            "step": 225
        },
        {
            "loss": 5.9579,
            "grad_norm": 0.388671875,
            "learning_rate": 7.937323358440934e-05,
            "epoch": 1.6400000000000001,
            "step": 230
        },
        {
            "loss": 6.0008,
            "grad_norm": 0.380859375,
            "learning_rate": 6.462696144011149e-05,
            "epoch": 1.6755555555555555,
            "step": 235
        },
        {
            "loss": 5.9854,
            "grad_norm": 0.36328125,
            "learning_rate": 5.130078565432089e-05,
            "epoch": 1.7111111111111112,
            "step": 240
        },
        {
            "eval_loss": 5.948043346405029,
            "eval_runtime": 38.0178,
            "eval_samples_per_second": 26.303,
            "eval_steps_per_second": 6.576,
            "epoch": 1.7111111111111112,
            "step": 240
        },
        {
            "loss": 5.9726,
            "grad_norm": 0.353515625,
            "learning_rate": 3.9438173442575e-05,
            "epoch": 1.7466666666666666,
            "step": 245
        },
        {
            "loss": 5.9527,
            "grad_norm": 0.259765625,
            "learning_rate": 2.9077818180237692e-05,
            "epoch": 1.7822222222222224,
            "step": 250
        },
        {
            "loss": 5.9995,
            "grad_norm": 0.326171875,
            "learning_rate": 2.025351319275137e-05,
            "epoch": 1.8177777777777777,
            "step": 255
        },
        {
            "loss": 5.9258,
            "grad_norm": 0.28515625,
            "learning_rate": 1.2994041528833267e-05,
            "epoch": 1.8533333333333335,
            "step": 260
        },
        {
            "loss": 5.9774,
            "grad_norm": 0.439453125,
            "learning_rate": 7.323082076153509e-06,
            "epoch": 1.8888888888888888,
            "step": 265
        },
        {
            "loss": 5.9818,
            "grad_norm": 0.310546875,
            "learning_rate": 3.2591323257248896e-06,
            "epoch": 1.9244444444444444,
            "step": 270
        },
        {
            "eval_loss": 5.94699239730835,
            "eval_runtime": 41.779,
            "eval_samples_per_second": 23.935,
            "eval_steps_per_second": 5.984,
            "epoch": 1.9244444444444444,
            "step": 270
        },
        {
            "loss": 5.9799,
            "grad_norm": 0.318359375,
            "learning_rate": 8.15448036932176e-07,
            "epoch": 1.96,
            "step": 275
        },
        {
            "loss": 5.9694,
            "grad_norm": 0.28125,
            "learning_rate": 0.0,
            "epoch": 1.9955555555555555,
            "step": 280
        },
        {
            "train_runtime": 2429.4723,
            "train_samples_per_second": 7.409,
            "train_steps_per_second": 0.115,
            "total_flos": 2.3927653715337216e+16,
            "train_loss": 7.133270195552281,
            "epoch": 1.9955555555555555,
            "step": 280
        }
    ],
    "depth=16": [
        {
            "eval_loss": 3.8452,
            "eval_runtime": 30.273,
            "eval_samples_per_second": 33.033,
            "eval_steps_per_second": 8.258,
            "epoch": 0.035555555555555556,
            "step": 5
        },
        {
            "loss": 3.9654,
            "grad_norm": 10.875,
            "learning_rate": 0.0005,
            "epoch": 0.035555555555555556,
            "step": 5
        },
        {
            "loss": 3.5291,
            "grad_norm": 1.6328125,
            "learning_rate": 0.0004995922759815339,
            "epoch": 0.07111111111111111,
            "step": 10
        },
        {
            "loss": 3.4002,
            "grad_norm": 1.3984375,
            "learning_rate": 0.0004983704338371376,
            "epoch": 0.10666666666666667,
            "step": 15
        },
        {
            "loss": 3.2958,
            "grad_norm": 0.9375,
            "learning_rate": 0.0004963384589619233,
            "epoch": 0.14222222222222222,
            "step": 20
        },
        {
            "loss": 3.2622,
            "grad_norm": 0.796875,
            "learning_rate": 0.0004935029792355834,
            "epoch": 0.17777777777777778,
            "step": 25
        },
        {
            "loss": 3.2596,
            "grad_norm": 0.73828125,
            "learning_rate": 0.0004898732434036243,
            "epoch": 0.21333333333333335,
            "step": 30
        },
        {
            "eval_loss": 3.0581626892089844,
            "eval_runtime": 30.273,
            "eval_samples_per_second": 33.033,
            "eval_steps_per_second": 8.258,
            "epoch": 0.21333333333333335,
            "step": 30
        },
        {
            "loss": 3.2186,
            "grad_norm": 0.734375,
            "learning_rate": 0.0004854610909098812,
            "epoch": 0.24888888888888888,
            "step": 35
        },
        {
            "loss": 3.202,
            "grad_norm": 0.85546875,
            "learning_rate": 0.00048028091327871256,
            "epoch": 0.28444444444444444,
            "step": 40
        },
        {
            "loss": 3.2243,
            "grad_norm": 0.75390625,
            "learning_rate": 0.0004743496071728396,
            "epoch": 0.32,
            "step": 45
        },
        {
            "loss": 3.1992,
            "grad_norm": 0.71875,
            "learning_rate": 0.00046768651927994433,
            "epoch": 0.35555555555555557,
            "step": 50
        },
        {
            "loss": 3.2183,
            "grad_norm": 0.640625,
            "learning_rate": 0.0004603133832077953,
            "epoch": 0.39111111111111113,
            "step": 55
        },
        {
            "loss": 3.1619,
            "grad_norm": 0.734375,
            "learning_rate": 0.0004522542485937369,
            "epoch": 0.4266666666666667,
            "step": 60
        },
        {
            "eval_loss": 3.018143892288208,
            "eval_runtime": 27.7775,
            "eval_samples_per_second": 36.0,
            "eval_steps_per_second": 9.0,
            "epoch": 0.4266666666666667,
            "step": 60
        },
        {
            "loss": 3.193,
            "grad_norm": 0.734375,
            "learning_rate": 0.00044353540265977065,
            "epoch": 0.4622222222222222,
            "step": 65
        },
        {
            "loss": 3.2123,
            "grad_norm": 0.91015625,
            "learning_rate": 0.00043418528446910123,
            "epoch": 0.49777777777777776,
            "step": 70
        },
        {
            "loss": 3.1843,
            "grad_norm": 0.64453125,
            "learning_rate": 0.00042423439216382345,
            "epoch": 0.5333333333333333,
            "step": 75
        },
        {
            "loss": 3.1451,
            "grad_norm": 0.67578125,
            "learning_rate": 0.0004137151834863213,
            "epoch": 0.5688888888888889,
            "step": 80
        },
        {
            "loss": 3.1661,
            "grad_norm": 0.61328125,
            "learning_rate": 0.00040266196990885957,
            "epoch": 0.6044444444444445,
            "step": 85
        },
        {
            "loss": 3.139,
            "grad_norm": 0.640625,
            "learning_rate": 0.0003911108047166924,
            "epoch": 0.64,
            "step": 90
        },
        {
            "eval_loss": 2.98917293548584,
            "eval_runtime": 30.3386,
            "eval_samples_per_second": 32.961,
            "eval_steps_per_second": 8.24,
            "epoch": 0.64,
            "step": 90
        },
        {
            "loss": 3.1327,
            "grad_norm": 0.71484375,
            "learning_rate": 0.0003790993654097405,
            "epoch": 0.6755555555555556,
            "step": 95
        },
        {
            "loss": 3.1365,
            "grad_norm": 0.6328125,
            "learning_rate": 0.00036666683080641843,
            "epoch": 0.7111111111111111,
            "step": 100
        },
        {
            "loss": 3.1751,
            "grad_norm": 0.703125,
            "learning_rate": 0.00035385375325047166,
            "epoch": 0.7466666666666667,
            "step": 105
        },
        {
            "loss": 3.1024,
            "grad_norm": 0.7109375,
            "learning_rate": 0.00034070192633766023,
            "epoch": 0.7822222222222223,
            "step": 110
        },
        {
            "loss": 3.0963,
            "grad_norm": 0.69921875,
            "learning_rate": 0.00032725424859373687,
            "epoch": 0.8177777777777778,
            "step": 115
        },
        {
            "loss": 3.1252,
            "grad_norm": 0.60546875,
            "learning_rate": 0.0003135545835483718,
            "epoch": 0.8533333333333334,
            "step": 120
        },
        {
            "eval_loss": 2.973820686340332,
            "eval_runtime": 30.3038,
            "eval_samples_per_second": 32.999,
            "eval_steps_per_second": 8.25,
            "epoch": 0.8533333333333334,
            "step": 120
        },
        {
            "loss": 3.1235,
            "grad_norm": 0.64453125,
            "learning_rate": 0.0002996476166614364,
            "epoch": 0.8888888888888888,
            "step": 125
        },
        {
            "loss": 3.1352,
            "grad_norm": 0.65625,
            "learning_rate": 0.00028557870956832135,
            "epoch": 0.9244444444444444,
            "step": 130
        },
        {
            "loss": 3.1079,
            "grad_norm": 0.5625,
            "learning_rate": 0.00027139375211970997,
            "epoch": 0.96,
            "step": 135
        },
        {
            "loss": 3.1279,
            "grad_norm": 0.53515625,
            "learning_rate": 0.00025713901269842405,
            "epoch": 0.9955555555555555,
            "step": 140
        },
        {
            "loss": 3.5561,
            "grad_norm": 0.69140625,
            "learning_rate": 0.00024286098730157596,
            "epoch": 1.0355555555555556,
            "step": 145
        },
        {
            "loss": 2.9363,
            "grad_norm": 0.66796875,
            "learning_rate": 0.00022860624788029015,
            "epoch": 1.0711111111111111,
            "step": 150
        },
        {
            "eval_loss": 2.9664695262908936,
            "eval_runtime": 31.7126,
            "eval_samples_per_second": 31.533,
            "eval_steps_per_second": 7.883,
            "epoch": 1.0711111111111111,
            "step": 150
        },
        {
            "loss": 2.9317,
            "grad_norm": 0.59765625,
            "learning_rate": 0.00021442129043167875,
            "epoch": 1.1066666666666667,
            "step": 155
        },
        {
            "loss": 2.9173,
            "grad_norm": 0.60546875,
            "learning_rate": 0.00020035238333856371,
            "epoch": 1.1422222222222222,
            "step": 160
        },
        {
            "loss": 2.9179,
            "grad_norm": 0.6875,
            "learning_rate": 0.00018644541645162832,
            "epoch": 1.1777777777777778,
            "step": 165
        },
        {
            "loss": 2.9636,
            "grad_norm": 0.671875,
            "learning_rate": 0.00017274575140626317,
            "epoch": 1.2133333333333334,
            "step": 170
        },
        {
            "loss": 2.9092,
            "grad_norm": 0.60546875,
            "learning_rate": 0.00015929807366233978,
            "epoch": 1.248888888888889,
            "step": 175
        },
        {
            "loss": 2.9239,
            "grad_norm": 0.73046875,
            "learning_rate": 0.0001461462467495284,
            "epoch": 1.2844444444444445,
            "step": 180
        },
        {
            "eval_loss": 2.9573817253112793,
            "eval_runtime": 32.8723,
            "eval_samples_per_second": 30.421,
            "eval_steps_per_second": 7.605,
            "epoch": 1.2844444444444445,
            "step": 180
        },
        {
            "loss": 2.9514,
            "grad_norm": 0.58203125,
            "learning_rate": 0.00013333316919358158,
            "epoch": 1.32,
            "step": 185
        },
        {
            "loss": 2.9145,
            "grad_norm": 0.59765625,
            "learning_rate": 0.00012090063459025954,
            "epoch": 1.3555555555555556,
            "step": 190
        },
        {
            "loss": 2.9217,
            "grad_norm": 1.109375,
            "learning_rate": 0.00010888919528330776,
            "epoch": 1.3911111111111112,
            "step": 195
        },
        {
            "loss": 2.8975,
            "grad_norm": 0.609375,
            "learning_rate": 9.733803009114044e-05,
            "epoch": 1.4266666666666667,
            "step": 200
        },
        {
            "loss": 2.9468,
            "grad_norm": 0.5390625,
            "learning_rate": 8.628481651367875e-05,
            "epoch": 1.462222222222222,
            "step": 205
        },
        {
            "loss": 2.9278,
            "grad_norm": 0.59765625,
            "learning_rate": 7.576560783617667e-05,
            "epoch": 1.4977777777777779,
            "step": 210
        },
        {
            "eval_loss": 2.9549906253814697,
            "eval_runtime": 30.2825,
            "eval_samples_per_second": 33.022,
            "eval_steps_per_second": 8.256,
            "epoch": 1.4977777777777779,
            "step": 210
        },
        {
            "loss": 2.9369,
            "grad_norm": 0.5703125,
            "learning_rate": 6.581471553089874e-05,
            "epoch": 1.5333333333333332,
            "step": 215
        },
        {
            "loss": 2.9139,
            "grad_norm": 0.62890625,
            "learning_rate": 5.646459734022938e-05,
            "epoch": 1.568888888888889,
            "step": 220
        },
        {
            "loss": 2.9707,
            "grad_norm": 0.5703125,
            "learning_rate": 4.7745751406263163e-05,
            "epoch": 1.6044444444444443,
            "step": 225
        },
        {
            "loss": 2.9593,
            "grad_norm": 0.578125,
            "learning_rate": 3.968661679220467e-05,
            "epoch": 1.6400000000000001,
            "step": 230
        },
        {
            "loss": 2.9394,
            "grad_norm": 0.58203125,
            "learning_rate": 3.231348072005574e-05,
            "epoch": 1.6755555555555555,
            "step": 235
        },
        {
            "loss": 2.9063,
            "grad_norm": 0.58203125,
            "learning_rate": 2.5650392827160445e-05,
            "epoch": 1.7111111111111112,
            "step": 240
        },
        {
            "eval_loss": 2.9544947147369385,
            "eval_runtime": 32.1012,
            "eval_samples_per_second": 31.152,
            "eval_steps_per_second": 7.788,
            "epoch": 1.7111111111111112,
            "step": 240
        },
        {
            "loss": 2.9103,
            "grad_norm": 0.55078125,
            "learning_rate": 1.97190867212875e-05,
            "epoch": 1.7466666666666666,
            "step": 245
        },
        {
            "loss": 2.9219,
            "grad_norm": 0.56640625,
            "learning_rate": 1.4538909090118846e-05,
            "epoch": 1.7822222222222224,
            "step": 250
        },
        {
            "loss": 2.9239,
            "grad_norm": 0.546875,
            "learning_rate": 1.0126756596375685e-05,
            "epoch": 1.8177777777777777,
            "step": 255
        },
        {
            "loss": 2.8917,
            "grad_norm": 0.59375,
            "learning_rate": 6.497020764416634e-06,
            "epoch": 1.8533333333333335,
            "step": 260
        },
        {
            "loss": 2.9259,
            "grad_norm": 0.62109375,
            "learning_rate": 3.6615410380767543e-06,
            "epoch": 1.8888888888888888,
            "step": 265
        },
        {
            "loss": 2.9125,
            "grad_norm": 0.546875,
            "learning_rate": 1.6295661628624448e-06,
            "epoch": 1.9244444444444444,
            "step": 270
        },
        {
            "eval_loss": 2.95438814163208,
            "eval_runtime": 30.9062,
            "eval_samples_per_second": 32.356,
            "eval_steps_per_second": 8.089,
            "epoch": 1.9244444444444444,
            "step": 270
        },
        {
            "loss": 2.9421,
            "grad_norm": 0.58984375,
            "learning_rate": 4.07724018466088e-07,
            "epoch": 1.96,
            "step": 275
        },
        {
            "loss": 2.8941,
            "grad_norm": 0.62890625,
            "learning_rate": 0.0,
            "epoch": 1.9955555555555555,
            "step": 280
        },
        {
            "train_runtime": 1904.5608,
            "train_samples_per_second": 9.451,
            "train_steps_per_second": 0.147,
            "total_flos": 2.126506390025011e+16,
            "train_loss": 3.0857861280441283,
            "epoch": 1.9955555555555555,
            "step": 280
        }
    ],
    "depth=20_num_heads=12_mlp_exp=3.5_embed_size=1024": [
        {
            "loss": 5.3412,
            "grad_norm": 8.375,
            "learning_rate": 0.0002,
            "epoch": 0.035555555555555556,
            "step": 5
        },
        {
            "loss": 4.3399,
            "grad_norm": 3.5625,
            "learning_rate": 0.00019983691039261357,
            "epoch": 0.07111111111111111,
            "step": 10
        },
        {
            "loss": 3.9047,
            "grad_norm": 2.3125,
            "learning_rate": 0.00019934817353485501,
            "epoch": 0.10666666666666667,
            "step": 15
        },
        {
            "loss": 3.656,
            "grad_norm": 1.6484375,
            "learning_rate": 0.00019853538358476932,
            "epoch": 0.14222222222222222,
            "step": 20
        },
        {
            "loss": 3.5471,
            "grad_norm": 1.5234375,
            "learning_rate": 0.00019740119169423337,
            "epoch": 0.17777777777777778,
            "step": 25
        },
        {
            "loss": 3.4844,
            "grad_norm": 1.4609375,
            "learning_rate": 0.00019594929736144976,
            "epoch": 0.21333333333333335,
            "step": 30
        },
        {
            "eval_loss": 3.1215550899505615,
            "eval_runtime": 22.9055,
            "eval_samples_per_second": 43.658,
            "eval_steps_per_second": 10.914,
            "epoch": 0.21333333333333335,
            "step": 30
        },
        {
            "loss": 3.4009,
            "grad_norm": 1.296875,
            "learning_rate": 0.00019418443636395248,
            "epoch": 0.24888888888888888,
            "step": 35
        },
        {
            "loss": 3.3513,
            "grad_norm": 1.203125,
            "learning_rate": 0.000192112365311485,
            "epoch": 0.28444444444444444,
            "step": 40
        },
        {
            "loss": 3.3575,
            "grad_norm": 1.171875,
            "learning_rate": 0.00018973984286913584,
            "epoch": 0.32,
            "step": 45
        },
        {
            "loss": 3.3158,
            "grad_norm": 1.09375,
            "learning_rate": 0.00018707460771197774,
            "epoch": 0.35555555555555557,
            "step": 50
        },
        {
            "loss": 3.3268,
            "grad_norm": 1.140625,
            "learning_rate": 0.00018412535328311814,
            "epoch": 0.39111111111111113,
            "step": 55
        },
        {
            "loss": 3.2623,
            "grad_norm": 0.9921875,
            "learning_rate": 0.00018090169943749476,
            "epoch": 0.4266666666666667,
            "step": 60
        },
        {
            "eval_loss": 3.0373966693878174,
            "eval_runtime": 22.8001,
            "eval_samples_per_second": 43.86,
            "eval_steps_per_second": 10.965,
            "epoch": 0.4266666666666667,
            "step": 60
        },
        {
            "loss": 3.2884,
            "grad_norm": 0.921875,
            "learning_rate": 0.00017741416106390826,
            "epoch": 0.4622222222222222,
            "step": 65
        },
        {
            "loss": 3.2909,
            "grad_norm": 0.8515625,
            "learning_rate": 0.0001736741137876405,
            "epoch": 0.49777777777777776,
            "step": 70
        },
        {
            "loss": 3.267,
            "grad_norm": 0.9140625,
            "learning_rate": 0.00016969375686552937,
            "epoch": 0.5333333333333333,
            "step": 75
        },
        {
            "loss": 3.2196,
            "grad_norm": 0.97265625,
            "learning_rate": 0.00016548607339452853,
            "epoch": 0.5688888888888889,
            "step": 80
        },
        {
            "loss": 3.2419,
            "grad_norm": 1.0546875,
            "learning_rate": 0.00016106478796354382,
            "epoch": 0.6044444444444445,
            "step": 85
        },
        {
            "loss": 3.2137,
            "grad_norm": 0.92578125,
            "learning_rate": 0.00015644432188667695,
            "epoch": 0.64,
            "step": 90
        },
        {
            "eval_loss": 3.0072317123413086,
            "eval_runtime": 22.8256,
            "eval_samples_per_second": 43.81,
            "eval_steps_per_second": 10.953,
            "epoch": 0.64,
            "step": 90
        },
        {
            "loss": 3.2137,
            "grad_norm": 0.82421875,
            "learning_rate": 0.0001516397461638962,
            "epoch": 0.6755555555555556,
            "step": 95
        },
        {
            "loss": 3.2129,
            "grad_norm": 0.88671875,
            "learning_rate": 0.00014666673232256738,
            "epoch": 0.7111111111111111,
            "step": 100
        },
        {
            "loss": 3.2478,
            "grad_norm": 0.84765625,
            "learning_rate": 0.00014154150130018866,
            "epoch": 0.7466666666666667,
            "step": 105
        },
        {
            "loss": 3.181,
            "grad_norm": 0.83203125,
            "learning_rate": 0.0001362807705350641,
            "epoch": 0.7822222222222223,
            "step": 110
        },
        {
            "loss": 3.1775,
            "grad_norm": 0.9765625,
            "learning_rate": 0.00013090169943749476,
            "epoch": 0.8177777777777778,
            "step": 115
        },
        {
            "loss": 3.1955,
            "grad_norm": 0.8203125,
            "learning_rate": 0.00012542183341934872,
            "epoch": 0.8533333333333334,
            "step": 120
        },
        {
            "eval_loss": 2.9898929595947266,
            "eval_runtime": 22.8113,
            "eval_samples_per_second": 43.838,
            "eval_steps_per_second": 10.959,
            "epoch": 0.8533333333333334,
            "step": 120
        },
        {
            "loss": 3.2002,
            "grad_norm": 0.77734375,
            "learning_rate": 0.00011985904666457455,
            "epoch": 0.8888888888888888,
            "step": 125
        },
        {
            "loss": 3.2145,
            "grad_norm": 0.83203125,
            "learning_rate": 0.00011423148382732853,
            "epoch": 0.9244444444444444,
            "step": 130
        },
        {
            "loss": 3.1863,
            "grad_norm": 0.78125,
            "learning_rate": 0.00010855750084788398,
            "epoch": 0.96,
            "step": 135
        },
        {
            "loss": 3.2073,
            "grad_norm": 0.7734375,
            "learning_rate": 0.00010285560507936961,
            "epoch": 0.9955555555555555,
            "step": 140
        },
        {
            "loss": 3.7707,
            "grad_norm": 0.79296875,
            "learning_rate": 9.71443949206304e-05,
            "epoch": 1.0355555555555556,
            "step": 145
        },
        {
            "loss": 3.1473,
            "grad_norm": 0.83203125,
            "learning_rate": 9.144249915211605e-05,
            "epoch": 1.0711111111111111,
            "step": 150
        },
        {
            "eval_loss": 2.985212802886963,
            "eval_runtime": 22.8099,
            "eval_samples_per_second": 43.841,
            "eval_steps_per_second": 10.96,
            "epoch": 1.0711111111111111,
            "step": 150
        },
        {
            "loss": 3.1475,
            "grad_norm": 0.7578125,
            "learning_rate": 8.57685161726715e-05,
            "epoch": 1.1066666666666667,
            "step": 155
        },
        {
            "loss": 3.1372,
            "grad_norm": 0.80078125,
            "learning_rate": 8.014095333542548e-05,
            "epoch": 1.1422222222222222,
            "step": 160
        },
        {
            "loss": 3.1292,
            "grad_norm": 0.7421875,
            "learning_rate": 7.457816658065134e-05,
            "epoch": 1.1777777777777778,
            "step": 165
        },
        {
            "loss": 3.172,
            "grad_norm": 0.73828125,
            "learning_rate": 6.909830056250527e-05,
            "epoch": 1.2133333333333334,
            "step": 170
        },
        {
            "loss": 3.1207,
            "grad_norm": 0.77734375,
            "learning_rate": 6.371922946493591e-05,
            "epoch": 1.248888888888889,
            "step": 175
        },
        {
            "loss": 3.1365,
            "grad_norm": 0.7734375,
            "learning_rate": 5.845849869981137e-05,
            "epoch": 1.2844444444444445,
            "step": 180
        },
        {
            "eval_loss": 2.980379343032837,
            "eval_runtime": 22.8185,
            "eval_samples_per_second": 43.824,
            "eval_steps_per_second": 10.956,
            "epoch": 1.2844444444444445,
            "step": 180
        },
        {
            "loss": 3.1762,
            "grad_norm": 0.75390625,
            "learning_rate": 5.333326767743263e-05,
            "epoch": 1.32,
            "step": 185
        },
        {
            "loss": 3.1276,
            "grad_norm": 0.734375,
            "learning_rate": 4.836025383610382e-05,
            "epoch": 1.3555555555555556,
            "step": 190
        },
        {
            "loss": 3.1328,
            "grad_norm": 0.796875,
            "learning_rate": 4.355567811332311e-05,
            "epoch": 1.3911111111111112,
            "step": 195
        },
        {
            "loss": 3.108,
            "grad_norm": 0.7734375,
            "learning_rate": 3.893521203645618e-05,
            "epoch": 1.4266666666666667,
            "step": 200
        },
        {
            "loss": 3.1648,
            "grad_norm": 0.7265625,
            "learning_rate": 3.45139266054715e-05,
            "epoch": 1.462222222222222,
            "step": 205
        },
        {
            "loss": 3.1447,
            "grad_norm": 0.765625,
            "learning_rate": 3.030624313447067e-05,
            "epoch": 1.4977777777777779,
            "step": 210
        },
        {
            "eval_loss": 2.979733467102051,
            "eval_runtime": 22.8984,
            "eval_samples_per_second": 43.671,
            "eval_steps_per_second": 10.918,
            "epoch": 1.4977777777777779,
            "step": 210
        },
        {
            "loss": 3.1499,
            "grad_norm": 0.69140625,
            "learning_rate": 2.6325886212359498e-05,
            "epoch": 1.5333333333333332,
            "step": 215
        },
        {
            "loss": 3.1351,
            "grad_norm": 0.8125,
            "learning_rate": 2.2585838936091754e-05,
            "epoch": 1.568888888888889,
            "step": 220
        },
        {
            "loss": 3.1895,
            "grad_norm": 0.72265625,
            "learning_rate": 1.9098300562505266e-05,
            "epoch": 1.6044444444444443,
            "step": 225
        },
        {
            "loss": 3.1766,
            "grad_norm": 0.82421875,
            "learning_rate": 1.587464671688187e-05,
            "epoch": 1.6400000000000001,
            "step": 230
        },
        {
            "loss": 3.1662,
            "grad_norm": 0.7421875,
            "learning_rate": 1.2925392288022298e-05,
            "epoch": 1.6755555555555555,
            "step": 235
        },
        {
            "loss": 3.1177,
            "grad_norm": 0.78125,
            "learning_rate": 1.026015713086418e-05,
            "epoch": 1.7111111111111112,
            "step": 240
        },
        {
            "eval_loss": 2.9791505336761475,
            "eval_runtime": 22.9053,
            "eval_samples_per_second": 43.658,
            "eval_steps_per_second": 10.915,
            "epoch": 1.7111111111111112,
            "step": 240
        },
        {
            "loss": 3.1303,
            "grad_norm": 0.75390625,
            "learning_rate": 7.887634688515e-06,
            "epoch": 1.7466666666666666,
            "step": 245
        },
        {
            "loss": 3.1362,
            "grad_norm": 0.75,
            "learning_rate": 5.8155636360475385e-06,
            "epoch": 1.7822222222222224,
            "step": 250
        },
        {
            "loss": 3.1533,
            "grad_norm": 0.7421875,
            "learning_rate": 4.050702638550275e-06,
            "epoch": 1.8177777777777777,
            "step": 255
        },
        {
            "loss": 3.1045,
            "grad_norm": 0.7578125,
            "learning_rate": 2.5988083057666533e-06,
            "epoch": 1.8533333333333335,
            "step": 260
        },
        {
            "loss": 3.1483,
            "grad_norm": 0.74609375,
            "learning_rate": 1.4646164152307018e-06,
            "epoch": 1.8888888888888888,
            "step": 265
        },
        {
            "loss": 3.125,
            "grad_norm": 0.765625,
            "learning_rate": 6.518264651449779e-07,
            "epoch": 1.9244444444444444,
            "step": 270
        },
        {
            "eval_loss": 2.9793009757995605,
            "eval_runtime": 22.8225,
            "eval_samples_per_second": 43.816,
            "eval_steps_per_second": 10.954,
            "epoch": 1.9244444444444444,
            "step": 270
        },
        {
            "loss": 3.1582,
            "grad_norm": 0.7421875,
            "learning_rate": 1.630896073864352e-07,
            "epoch": 1.96,
            "step": 275
        },
        {
            "loss": 3.1051,
            "grad_norm": 0.77734375,
            "learning_rate": 0.0,
            "epoch": 1.9955555555555555,
            "step": 280
        },
        {
            "train_runtime": 1446.8109,
            "train_samples_per_second": 12.441,
            "train_steps_per_second": 0.194,
            "total_flos": 2.215308003798221e+16,
            "train_loss": 3.2938842739377705,
            "epoch": 1.9955555555555555,
            "step": 280
        }
    ]
}